{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNp3wuXgP6Jgg1N3KxDiaLp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgl2000/comp559_ml_with_graphs/blob/main/comp_559_hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMP 559 HW 3\n",
        "@author: Gaole Dai (gd25)\n",
        "\n"
      ],
      "metadata": {
        "id": "OMwQiqR2x3Gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2"
      ],
      "metadata": {
        "id": "New8PnDhx-IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the wine dataset\n",
        "X, y = load_wine(return_X_y=True)\n",
        "np.random.seed(2)\n",
        "\n",
        "# Randomly select 30% of the data to be unlabelled\n",
        "mask = np.random.choice(len(y), size=int(len(y) * 0.3), replace=False)\n",
        "y_missing = np.copy(y)\n",
        "y_missing[mask] = -1\n",
        "\n",
        "# Train the label propagation model\n",
        "lp_model = LabelPropagation(gamma=.25).fit(X, y_missing)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "y_true = y[mask]\n",
        "y_pred = lp_model.transduction_[mask]\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy for random selection: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5wuC9nPhtIm",
        "outputId": "5a43b18d-2f09-424b-b6a5-e3c1554360ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for random selection: 0.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the wine dataset\n",
        "X, y = load_wine(return_X_y=True)\n",
        "\n",
        "# Train a KMeans clustering model to obtain cluster labels\n",
        "n_clusters = int(len(y) * 0.7)\n",
        "kmeans_model = KMeans(n_clusters=n_clusters).fit(X)\n",
        "cluster_labels = list(kmeans_model.labels_)\n",
        "\n",
        "# Randomly select 30% of the data to be unlabelled\n",
        "indices = []\n",
        "num_elements_to_remove = int(len(y) * 0.7)\n",
        "\n",
        "indices = [cluster_labels.index(i) for i in range(num_elements_to_remove)]\n",
        "mask = [i for i in range(len(y)) if i not in indices]\n",
        "\n",
        "# Set the unlabelled data to -1\n",
        "y_missing = np.copy(y)\n",
        "y_missing[mask] = -1\n",
        "\n",
        "# Train the label propagation model\n",
        "lp_model = LabelPropagation(gamma=.25)\n",
        "lp_model.fit(X, y_missing)\n",
        "\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "y_true = y[mask]\n",
        "y_pred = lp_model.transduction_[mask]\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy for K-means clustering selection: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DajKLtudiF7w",
        "outputId": "508398db-8289-44d4-c46e-14aa5250490b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for K-means clustering selection: 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3"
      ],
      "metadata": {
        "id": "6dysrKO8yBdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install networkx==2.8.6\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwX75trWMt4B",
        "outputId": "0cad35bb-a423-4aac-e88e-0f06381b584f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting networkx==2.8.6\n",
            "  Downloading networkx-2.8.6-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: networkx\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.0\n",
            "    Uninstalling networkx-3.0:\n",
            "      Successfully uninstalled networkx-3.0\n",
            "Successfully installed networkx-2.8.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import csv\n",
        "\n",
        "# Read the edgelist from file\n",
        "G = nx.read_edgelist(\"cora.cites\")\n",
        "\n",
        "# Initialize dictionaries for node labels and features, and a dictionary for unique labels\n",
        "node_labels = {}\n",
        "node_features = {}\n",
        "unique_labels = {}\n",
        "\n",
        "# Open the file containing node information\n",
        "with open('cora.content') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter='\\t')\n",
        "\n",
        "    # Loop through each row in the file\n",
        "    for row in reader:\n",
        "\n",
        "        # If the label is not already in the unique_labels dictionary, add it\n",
        "        label = row[-1]\n",
        "        if label not in unique_labels:\n",
        "            unique_labels[label] = len(unique_labels)\n",
        "\n",
        "        # Add the label and features for the current node to the respective dictionaries\n",
        "        node_id = row[0]\n",
        "        node_labels[node_id] = unique_labels[label]\n",
        "        node_features[node_id] = row[1:-1]"
      ],
      "metadata": {
        "id": "PDD17PzOMNdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the connected components of the graph and obtain the largest connected component\n",
        "connected_components = [G.subgraph(c) for c in nx.connected_components(G)]\n",
        "largest_component = max(connected_components, key=len)\n",
        "\n",
        "# Get the nodes in the largest connected component\n",
        "largest_nodes = largest_component.nodes()\n",
        "\n",
        "# Get the labels and features for each node in the largest connected component\n",
        "largest_labels = np.array([node_labels[node] for node in largest_nodes])\n",
        "largest_features = np.array([node_features[node] for node in largest_nodes])\n"
      ],
      "metadata": {
        "id": "nO18QSAh7J-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "\n",
        "# Load the graph from the adjacency matrix\n",
        "adj_matrix = nx.adjacency_matrix(largest_component)\n",
        "\n",
        "# Define a range of values to try for the number of clusters\n",
        "n_clusters_range = range(2, 40)\n",
        "\n",
        "# Store the results in lists\n",
        "ARI_list = []\n",
        "labels_list = []\n",
        "\n",
        "# Loop over the range of values for the number of clusters\n",
        "for n_clusters in n_clusters_range:\n",
        "    # Apply spectral clustering to the adjacency matrix\n",
        "    spectral_cluster = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', assign_labels='cluster_qr', n_neighbors=15, random_state=5).fit(adj_matrix)\n",
        "    # Get the predicted labels\n",
        "    predict_label = spectral_cluster.labels_\n",
        "    \n",
        "    # Compute the adjusted Rand index between the predicted labels and the true labels\n",
        "    ARI = adjusted_rand_score(largest_labels, predict_label)\n",
        "    \n",
        "    # Append the ARI and predicted labels to the corresponding lists\n",
        "    ARI_list.append(ARI)\n",
        "    labels_list.append(predict_label)\n",
        "    \n",
        "# Find the index of the maximum ARI\n",
        "max_ARI_idx = np.argmax(ARI_list)\n",
        "\n",
        "# Get the number of clusters and predicted labels corresponding to the maximum ARI\n",
        "best_n_clusters = n_clusters_range[max_ARI_idx]\n",
        "best_predict_label = labels_list[max_ARI_idx]\n",
        "\n",
        "# Print the results\n",
        "print(f\"Best number of clusters: {best_n_clusters}\")\n",
        "print(f\"Adjusted Rand index: {ARI_list[max_ARI_idx]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-xx4L33CHY5",
        "outputId": "addaa093-8a8f-4c2e-e4f4-3b5206650327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-586a8ec0bd79>:5: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
            "  adj_matrix = nx.adjacency_matrix(largest_component)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best number of clusters: 30\n",
            "Adjusted Rand index: 0.33940973934500496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "\n",
        "# Define a range of values to try for the number of clusters\n",
        "n_clusters_range = range(2, 40)\n",
        "\n",
        "# Store the results in lists\n",
        "ARI_list = []\n",
        "labels_list = []\n",
        "\n",
        "# Loop over the range of values for the number of clusters\n",
        "for n_clusters in n_clusters_range:\n",
        "    # Apply spectral clustering to the adjacency matrix\n",
        "    spectral_cluster = SpectralClustering(n_clusters=n_clusters, affinity='nearest_neighbors', n_init =100 , n_neighbors =5, random_state =0).fit(largest_features)\n",
        "    # Get the predicted labels\n",
        "    predict_label = spectral_cluster.labels_\n",
        "    \n",
        "    # Compute the adjusted Rand index between the predicted labels and the true labels\n",
        "    ARI = adjusted_rand_score(largest_labels, predict_label)\n",
        "    \n",
        "    # Append the ARI and predicted labels to the corresponding lists\n",
        "    ARI_list.append(ARI)\n",
        "    labels_list.append(predict_label)\n",
        "    \n",
        "# Find the index of the maximum ARI\n",
        "max_ARI_idx = np.argmax(ARI_list)\n",
        "\n",
        "# Get the number of clusters and predicted labels corresponding to the maximum ARI\n",
        "best_n_clusters = n_clusters_range[max_ARI_idx]\n",
        "best_predict_label = labels_list[max_ARI_idx]\n",
        "\n",
        "# Print the results\n",
        "print(f\"Best number of clusters: {best_n_clusters}\")\n",
        "print(f\"Adjusted Rand index: {ARI_list[max_ARI_idx]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCgn6MPUnWzw",
        "outputId": "71d7a287-a16c-4f62-d7f5-8482c0acf3fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best number of clusters: 9\n",
            "Adjusted Rand index: 0.0985192999739339\n"
          ]
        }
      ]
    }
  ]
}